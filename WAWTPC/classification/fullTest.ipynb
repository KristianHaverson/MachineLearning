{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 13:38:51.524203: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-02 13:38:52.365268: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7f39200eb6a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from skimage import io, transform\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.patches import Rectangle\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import h5py\n",
    "import uproot\n",
    "import pickle\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    \"Event/myChargeArray*\",\n",
    "]\n",
    "def padTensorData(batch_data):\n",
    "\n",
    "    max_dim = max(batch_data.size(1), batch_data.size(2))\n",
    "    pad_width = max_dim - batch_data.size(2)\n",
    "    pad_height = max_dim - batch_data.size(1)\n",
    "    top_pad = pad_height // 2\n",
    "    bottom_pad = pad_height - top_pad\n",
    "    left_pad = pad_width // 2\n",
    "    right_pad = pad_width - left_pad\n",
    "    padded_tensor = F.pad(batch_data, (0,0,left_pad, right_pad, top_pad, bottom_pad), value=0)\n",
    "    return padded_tensor\n",
    "\n",
    "\n",
    "def generator2(files, label, batchSize):\n",
    "    for array in uproot.iterate(files, step_size=batchSize,filter_name=fields,  library=\"ak\"):\n",
    "        features = array[\"myChargeArray[3][3][256][512]\"].to_numpy()\n",
    "        features = features.astype(float)\n",
    "        features = np.sum(features, axis=2)\n",
    "        features = np.moveaxis(features, 1, -1)\n",
    "        \n",
    "        # find max pixel in image, from merged image\n",
    "        #merged_image = np.sum(features, axis=(3))\n",
    "\n",
    "        # features/=np.amax(merged_image, keepdims=True)\n",
    "        features /= np.amax(features, axis=(1,2,3), keepdims=True)\n",
    "\n",
    "        tensor_data = torch.from_numpy(np.array(features))\n",
    "        tensor_data = tensor_data.float()\n",
    "        padded_tensor_data = padTensorData(tensor_data)\n",
    "            \n",
    "\n",
    "        labels = np.full((batchSize, ), label)\n",
    "        yield padded_tensor_data , labels\n",
    "\n",
    "\n",
    "def numberOfBatches(dataloader):\n",
    "    number_of_batches=0\n",
    "    for images, labels in dataloader:\n",
    "        number_of_batches=number_of_batches+1\n",
    "    return number_of_batches\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_per_batch = 100 # number of entries per batch\n",
    "path = '/home/kris/Documents/coding/WAWTPC/krisTPCReco/TPCReco-kris/build/resources/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1Files = [path+'C12_ALPHA_1k_131MeV_250mbar_.root:TPCData']\n",
    "datasetGenerator1 = partial(generator2, files=class1Files,label=2, batchSize=entries_per_batch)\n",
    "dataloader1 = DataLoader(list(datasetGenerator1()))\n",
    "arrayEvents_c1=[]\n",
    "arrayLabels_c1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_images, batch_labels in dataloader1: # for each batch\n",
    "    batch_images = batch_images.squeeze(0)\n",
    "    batch_labels = batch_labels.squeeze(0)\n",
    "    batch_images = batch_images.permute(0, 3, 1, 2)\n",
    "    for event in range(entries_per_batch):              # for each event in batch [0->50]\n",
    "        arrayEvents_c1.append(batch_images[event])      # first is always zero?\n",
    "        arrayLabels_c1.append(batch_labels[event].item())\n",
    "number_of_batches_1 = numberOfBatches(dataloader1)\n",
    "del dataloader1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2Files = [path+'THREE_ALPHA_BE+_1k_131MeV_250mbar_.root:TPCData']\n",
    "datasetGenerator2 = partial(generator2, files=class2Files,label=3, batchSize=entries_per_batch)\n",
    "dataloader2 = DataLoader(list(datasetGenerator2()))\n",
    "arrayEvents_c2=[]\n",
    "arrayLabels_c2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m batch_images, batch_labels \u001b[39min\u001b[39;00m dataloader2: \u001b[39m# for each batch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     batch_images \u001b[39m=\u001b[39m batch_images\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m     batch_labels \u001b[39m=\u001b[39m batch_labels\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader2' is not defined"
     ]
    }
   ],
   "source": [
    "for batch_images, batch_labels in dataloader2: # for each batch\n",
    "    batch_images = batch_images.squeeze(0)\n",
    "    batch_labels = batch_labels.squeeze(0)\n",
    "    batch_images = batch_images.permute(0, 3, 1, 2)\n",
    "    for event in range(entries_per_batch):              # for each event in batch [0->50]\n",
    "        arrayEvents_c2.append(batch_images[event])      # first is always zero?\n",
    "        arrayLabels_c2.append(batch_labels[event].item())\n",
    "number_of_batches_2 = numberOfBatches(dataloader2)\n",
    "del dataloader2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entries_per_batch  100\n",
      "number_of_batches_1  10\n",
      "number_of_batches_2  10\n"
     ]
    }
   ],
   "source": [
    "print('entries_per_batch ',entries_per_batch)\n",
    "print('number_of_batches_1 ',number_of_batches_1)\n",
    "print('number_of_batches_2 ',number_of_batches_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "3\n",
      "512\n",
      "512\n",
      "label ===>  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(arrayEvents_c1))  #number of event\n",
    "print(len(arrayEvents_c1[0])) #channel\n",
    "print(len(arrayEvents_c1[0][0])) #X\n",
    "print(len(arrayEvents_c1[0][0][0])) #Y\n",
    "\n",
    "getEntry=1\n",
    "data  = arrayEvents_c2[getEntry]\n",
    "label = arrayLabels_c2[getEntry]\n",
    "\n",
    "print('label ===> ',label)\n",
    "fig, axis = plt.subplots()\n",
    "data = data.numpy().transpose((1, 2, 0))\n",
    "im = axis.imshow(data, origin='lower', aspect='auto')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train c1 set size: 700\n",
      "Test c1 set size: 300\n",
      "============================================\n",
      "Train c2 set size: 700\n",
      "Test c2 set size: 300\n",
      "Train set size: 1400\n",
      "Test set size: 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_c1_images, test_c1_images, train_c1_labels, test_c1_labels = train_test_split(arrayEvents_c1, arrayLabels_c1, test_size=0.3)\n",
    "del arrayEvents_c1\n",
    "del arrayLabels_c1\n",
    "\n",
    "train_c2_images, test_c2_images, train_c2_labels, test_c2_labels = train_test_split(arrayEvents_c2, arrayLabels_c2, test_size=0.3)\n",
    "del arrayEvents_c2\n",
    "del arrayLabels_c2\n",
    "\n",
    "del datasetGenerator1\n",
    "del datasetGenerator2\n",
    "\n",
    "print('Train c1 set size:', len(train_c1_images))\n",
    "print('Test c1 set size:', len(test_c1_images))\n",
    "print('============================================')\n",
    "print('Train c2 set size:', len(train_c2_images))\n",
    "print('Test c2 set size:', len(test_c2_images))\n",
    "\n",
    "# Concatenate class 1 images and labels\n",
    "train_images = np.concatenate((train_c1_images, train_c2_images))\n",
    "del train_c1_images\n",
    "del train_c2_images\n",
    "train_labels = np.concatenate((train_c1_labels, train_c2_labels))\n",
    "del train_c1_labels\n",
    "del train_c2_labels\n",
    "test_images = np.concatenate((test_c1_images, test_c2_images))\n",
    "del test_c1_images\n",
    "del test_c2_images\n",
    "test_labels = np.concatenate((test_c1_labels, test_c2_labels))\n",
    "del test_c1_labels\n",
    "del test_c2_labels\n",
    "\n",
    "print('Train set size:', len(train_images))\n",
    "print('Test set size:', len(test_images))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1400\n",
      "Test set size: 600\n",
      "Train set size: 1400\n",
      "Test set size: 600\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Combine the images and labels into a single list\n",
    "train_data = list(zip(train_images, train_labels))\n",
    "test_data = list(zip(test_images, test_labels))\n",
    "\n",
    "del train_images\n",
    "del train_labels\n",
    "del test_images\n",
    "del test_labels\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "# Unzip the shuffled data back into separate lists\n",
    "shuffled_train_images, shuffled_train_labels = zip(*train_data)\n",
    "shuffled_test_images, shuffled_test_labels = zip(*test_data)\n",
    "del train_data\n",
    "del test_data\n",
    "\n",
    "\n",
    "print('Train set size:', len(shuffled_train_images))\n",
    "print('Test set size:', len(shuffled_test_images))\n",
    "\n",
    "print('Train set size:', len(shuffled_train_labels))\n",
    "print('Test set size:', len(shuffled_test_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1400, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "hdf5_file = h5py.File(\"shuffled_train_images_tensor.h5\", \"w\")\n",
    "\n",
    "shuffled_train_images_tensor = torch.stack(shuffled_train_images)\n",
    "del shuffled_train_images\n",
    "print(type(shuffled_train_images_tensor))\n",
    "print(shuffled_train_images_tensor.shape)\n",
    "hdf5_file.create_dataset(\"images\", data=shuffled_train_images_tensor)\n",
    "del shuffled_train_images_tensor\n",
    "\n",
    "\n",
    "shuffled_train_labels_tensor = torch.tensor(shuffled_train_labels)\n",
    "del shuffled_train_labels\n",
    "print(type(shuffled_train_labels_tensor))\n",
    "print(shuffled_train_labels_tensor.shape)\n",
    "hdf5_file.create_dataset(\"labels\", data=shuffled_train_labels_tensor)\n",
    "del shuffled_train_labels_tensor\n",
    "\n",
    "hdf5_file.close()\n",
    "del hdf5_file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "hdf5_file = h5py.File(\"shuffled_test_images_tensor.h5\", \"w\")\n",
    "\n",
    "shuffled_test_images_tensor = torch.stack(shuffled_test_images)\n",
    "del shuffled_test_images\n",
    "print(type(shuffled_test_images_tensor))\n",
    "print(shuffled_test_images_tensor.shape)\n",
    "hdf5_file.create_dataset(\"images\", data=shuffled_test_images_tensor)\n",
    "del shuffled_test_images_tensor\n",
    "\n",
    "\n",
    "\n",
    "shuffled_test_labels_tensor = torch.tensor(shuffled_test_labels)\n",
    "print(type(shuffled_test_labels_tensor))\n",
    "print(shuffled_test_labels_tensor.shape)\n",
    "del shuffled_test_labels\n",
    "del shuffled_test_labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shuffled_test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m shuffled_test_labels_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(shuffled_test_labels)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(shuffled_test_labels_tensor))\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(shuffled_test_labels_tensor\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shuffled_test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "shuffled_test_labels_tensor = torch.tensor(shuffled_test_labels)\n",
    "print(type(shuffled_test_labels_tensor))\n",
    "print(shuffled_test_labels_tensor.shape)\n",
    "del shuffled_test_labels\n",
    "del shuffled_test_labels_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_ds = TensorDataset(shuffled_train_images_tensor, shuffled_train_labels_tensor)\n",
    "train_dl = DataLoader(train_ds, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = TensorDataset(shuffled_test_images_tensor, shuffled_test_labels_tensor)\n",
    "valid_dl = DataLoader(test_ds, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 512, 512])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataloaders = {'train': train_dl, 'val': valid_dl}\n",
    "dataset_sizes = {'train': len(train_ds), 'val': len(valid_ds)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kris/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/kris/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True) # <------------------------------------------------------------\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# initialise a fully connected layer with appropriate dimensions (num_ftrs x num_classes)\n",
    "model_ft.fc = nn.Linear(num_ftrs, 4) # <------------------------------------------------------------\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# set the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# set the optimiser\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.90)\n",
    "\n",
    "# decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "\n",
    "    # start a timer\n",
    "    since = time.time()\n",
    "\n",
    "    # track the best performing model\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # iterate over all epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # show the current epoch we are on\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # set model to training mode\n",
    "            else:\n",
    "                model.eval()   # set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward pass (track gradients if only in train mode)\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in train mode\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # track the performance statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # step the learning rate scheduler if in train mode\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            # keep track of the overall loss and accuracy over each epoch\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            print(f'{phase} loss: {epoch_loss:.4f}, acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # keep a deep copy of the best performing model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    # track the time taken\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'best val acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'_TensorSliceDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_ft \u001b[39m=\u001b[39m train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m);\n",
      "Cell \u001b[0;32mIn[87], line 28\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m running_corrects \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[39m# iterate over data\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m iteratorTRAIN:\n\u001b[1;32m     29\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py:243\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     sample_idx \u001b[39m=\u001b[39m idx \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcumulative_sizes[dataset_idx \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m--> 243\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets[dataset_idx][sample_idx]\n",
      "\u001b[0;31mTypeError\u001b[0m: '_TensorSliceDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=15);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 00:51:11.204901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-01 00:51:11.300015: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: CannotBeAwkward: SimHit\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/kris/Documents/coding/WAWTPC/ML/MachineLearningTPC/MachineLearning/WAWTPC/classification/TPCParser.py\", line 178, in generator\n",
      "    for array in uproot.iterate(files, step_size=batchSize,\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 193, in iterate\n",
      "    for item in hasbranches.iterate(\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 1080, in iterate\n",
      "    _ranges_or_baskets_to_arrays(\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 3041, in _ranges_or_baskets_to_arrays\n",
      "    arrays[cache_key] = interpretation.final_array(\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/interpretation/objects.py\", line 423, in final_array\n",
      "    output = library.finalize(\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/interpretation/library.py\", line 572, in finalize\n",
      "    interpretation.awkward_form(interpretation.branch.file).to_json()\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/interpretation/objects.py\", line 113, in awkward_form\n",
      "    return self._model.awkward_form(self._branch.file, context)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/containers.py\", line 691, in awkward_form\n",
      "    values_form = uproot._util.awkward_form(self._values, file, context)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/_util.py\", line 587, in awkward_form\n",
      "    return model.awkward_form(file, context)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/containers.py\", line 1063, in awkward_form\n",
      "    uproot._util.awkward_form(self._values, file, context),\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/_util.py\", line 587, in awkward_form\n",
      "    return model.awkward_form(file, context)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/model.py\", line 686, in awkward_form\n",
      "    raise uproot.interpretation.objects.CannotBeAwkward(\n",
      "\n",
      "uproot.interpretation.objects.CannotBeAwkward: SimHit\n",
      "\n",
      "\n",
      "2023-07-01 00:51:11.300075: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: CannotBeAwkward: SimHit\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/kris/Documents/coding/WAWTPC/ML/MachineLearningTPC/MachineLearning/WAWTPC/classification/TPCParser.py\", line 178, in generator\n",
      "    for array in uproot.iterate(files, step_size=batchSize,\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 193, in iterate\n",
      "    for item in hasbranches.iterate(\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 1080, in iterate\n",
      "    _ranges_or_baskets_to_arrays(\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 3041, in _ranges_or_baskets_to_arrays\n",
      "    arrays[cache_key] = interpretation.final_array(\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/interpretation/objects.py\", line 423, in final_array\n",
      "    output = library.finalize(\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/interpretation/library.py\", line 572, in finalize\n",
      "    interpretation.awkward_form(interpretation.branch.file).to_json()\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/interpretation/objects.py\", line 113, in awkward_form\n",
      "    return self._model.awkward_form(self._branch.file, context)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/containers.py\", line 691, in awkward_form\n",
      "    values_form = uproot._util.awkward_form(self._values, file, context)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/_util.py\", line 587, in awkward_form\n",
      "    return model.awkward_form(file, context)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/containers.py\", line 1063, in awkward_form\n",
      "    uproot._util.awkward_form(self._values, file, context),\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/_util.py\", line 587, in awkward_form\n",
      "    return model.awkward_form(file, context)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/model.py\", line 686, in awkward_form\n",
      "    raise uproot.interpretation.objects.CannotBeAwkward(\n",
      "\n",
      "uproot.interpretation.objects.CannotBeAwkward: SimHit\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} CannotBeAwkward: SimHit\nTraceback (most recent call last):\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/kris/Documents/coding/WAWTPC/ML/MachineLearningTPC/MachineLearning/WAWTPC/classification/TPCParser.py\", line 178, in generator\n    for array in uproot.iterate(files, step_size=batchSize,\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 193, in iterate\n    for item in hasbranches.iterate(\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 1080, in iterate\n    _ranges_or_baskets_to_arrays(\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 3041, in _ranges_or_baskets_to_arrays\n    arrays[cache_key] = interpretation.final_array(\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/interpretation/objects.py\", line 423, in final_array\n    output = library.finalize(\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/interpretation/library.py\", line 572, in finalize\n    interpretation.awkward_form(interpretation.branch.file).to_json()\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/interpretation/objects.py\", line 113, in awkward_form\n    return self._model.awkward_form(self._branch.file, context)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/containers.py\", line 691, in awkward_form\n    values_form = uproot._util.awkward_form(self._values, file, context)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/_util.py\", line 587, in awkward_form\n    return model.awkward_form(file, context)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/containers.py\", line 1063, in awkward_form\n    uproot._util.awkward_form(self._values, file, context),\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/_util.py\", line 587, in awkward_form\n    return model.awkward_form(file, context)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/model.py\", line 686, in awkward_form\n    raise uproot.interpretation.objects.CannotBeAwkward(\n\nuproot.interpretation.objects.CannotBeAwkward: SimHit\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 22\u001b[0m\n\u001b[1;32m     14\u001b[0m train_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_generator(\n\u001b[1;32m     15\u001b[0m      datasetGenerator,\n\u001b[1;32m     16\u001b[0m      output_signature\u001b[39m=\u001b[39m(\n\u001b[1;32m     17\u001b[0m          tf\u001b[39m.\u001b[39mTensorSpec(shape\u001b[39m=\u001b[39m(\u001b[39m100\u001b[39m,) \u001b[39m+\u001b[39m (projections\u001b[39m.\u001b[39mshape), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32),\n\u001b[1;32m     18\u001b[0m     ))\n\u001b[1;32m     19\u001b[0m \u001b[39m#dataBeP = io.getDataML(path+filename1)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m#dataC12 = io.getDataML(path+filename2)\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfor\u001b[39;00m aBatch \u001b[39min\u001b[39;00m train_dataset\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m):\n\u001b[1;32m     24\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:797\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    796\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 797\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    798\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    799\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:780\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 780\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    781\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    782\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    783\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    785\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    786\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3016\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3014\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3015\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3016\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3017\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   3018\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mUnknownError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} CannotBeAwkward: SimHit\nTraceback (most recent call last):\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/kris/Documents/coding/WAWTPC/ML/MachineLearningTPC/MachineLearning/WAWTPC/classification/TPCParser.py\", line 178, in generator\n    for array in uproot.iterate(files, step_size=batchSize,\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 193, in iterate\n    for item in hasbranches.iterate(\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 1080, in iterate\n    _ranges_or_baskets_to_arrays(\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 3041, in _ranges_or_baskets_to_arrays\n    arrays[cache_key] = interpretation.final_array(\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/interpretation/objects.py\", line 423, in final_array\n    output = library.finalize(\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/interpretation/library.py\", line 572, in finalize\n    interpretation.awkward_form(interpretation.branch.file).to_json()\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/interpretation/objects.py\", line 113, in awkward_form\n    return self._model.awkward_form(self._branch.file, context)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/containers.py\", line 691, in awkward_form\n    values_form = uproot._util.awkward_form(self._values, file, context)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/_util.py\", line 587, in awkward_form\n    return model.awkward_form(file, context)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/containers.py\", line 1063, in awkward_form\n    uproot._util.awkward_form(self._values, file, context),\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/_util.py\", line 587, in awkward_form\n    return model.awkward_form(file, context)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/uproot/model.py\", line 686, in awkward_form\n    raise uproot.interpretation.objects.CannotBeAwkward(\n\nuproot.interpretation.objects.CannotBeAwkward: SimHit\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 00:05:06.796271: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-01 00:05:15.910875: W tensorflow/core/framework/op_kernel.cc:1818] INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (100, 3, 3, 512, 3) where an element of shape (None, 512, 512, 3) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (100, 3, 3, 512, 3) where an element of shape (None, 512, 512, 3) was expected.\n",
      "\n",
      "\n",
      "2023-07-01 00:05:15.911321: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (100, 3, 3, 512, 3) where an element of shape (None, 512, 512, 3) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (100, 3, 3, 512, 3) where an element of shape (None, 512, 512, 3) was expected.\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element of shape (100, 3, 3, 512, 3) where an element of shape (None, 512, 512, 3) was expected.\nTraceback (most recent call last):\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (100, 3, 3, 512, 3) where an element of shape (None, 512, 512, 3) was expected.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 17\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[39myield\u001b[39;00m data\n\u001b[1;32m     12\u001b[0m train_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_generator(\n\u001b[1;32m     13\u001b[0m     generator_wrapper,\n\u001b[1;32m     14\u001b[0m     output_signature\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mTensorSpec(shape\u001b[39m=\u001b[39m(\u001b[39mNone\u001b[39;00m, \u001b[39m512\u001b[39m, \u001b[39m512\u001b[39m, \u001b[39m3\u001b[39m), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfor\u001b[39;00m batch_data \u001b[39min\u001b[39;00m train_dataset\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m):\n\u001b[1;32m     18\u001b[0m     \u001b[39mprint\u001b[39m(batch_data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:797\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    796\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 797\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    798\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    799\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:780\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 780\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    781\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    782\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    783\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    785\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    786\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3016\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3014\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3015\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3016\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3017\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   3018\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element of shape (100, 3, 3, 512, 3) where an element of shape (None, 512, 512, 3) was expected.\nTraceback (most recent call last):\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (100, 3, 3, 512, 3) where an element of shape (None, 512, 512, 3) was expected.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 00:05:17.557835: W tensorflow/core/framework/op_kernel.cc:1818] INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (100, 3, 3, 512, 3) where an element of shape (None, 512, 512, 3) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (100, 3, 3, 512, 3) where an element of shape (None, 512, 512, 3) was expected.\n",
      "\n",
      "\n",
      "2023-07-01 00:05:17.557930: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (100, 3, 3, 512, 3) where an element of shape (None, 512, 512, 3) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/kris/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (100, 3, 3, 512, 3) where an element of shape (None, 512, 512, 3) was expected.\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kris/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/kris/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
