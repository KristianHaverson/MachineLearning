{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.patches import Rectangle\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets,models,transforms       \n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "cudnn.benchmark = True\n",
    "plt.ion()\n",
    "from functools import partial\n",
    "import uproot\n",
    "\n",
    "#import utility_functions as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'myChargeArray[3][3][256][512]': [[[[0, ..., 0], ...], ...], ...]}, ...]\n"
     ]
    }
   ],
   "source": [
    "import TPCParser as io\n",
    "importlib.reload(io)\n",
    "\n",
    "path = '/home/kris/Documents/coding/WAWTPC/krisTPCReco/TPCReco-kris/build/resources/'\n",
    "filename1 = 'out.root'\n",
    "\n",
    "file = uproot.open(path+filename1)\n",
    "\n",
    "# Define the branch name\n",
    "branch_name = \"myChargeArray[3][3][256][512]\"\n",
    "\n",
    "# Iterate through the specified branch\n",
    "for array in uproot.iterate(file[\"TPCData/Event\"][branch_name], library=\"ak\"):\n",
    "    print(array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = io.parseChargeMaps(path+filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TPCParser as io\n",
    "importlib.reload(io)\n",
    "normMergedImage = io.getMergedImages(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3546116553.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[49], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    event = 0\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# <> SETUP PLOT <> #\n",
    "event = 0\n",
    "\n",
    "fig, axis = plt.subplots()\n",
    "im = axis.imshow(normMergedImage[event], origin='lower', aspect='auto')\n",
    "\n",
    "###############################################\n",
    "# <> SETUP PLOT <> #\n",
    "\n",
    "projNames = (\"U\", \"V\", \"W\")\n",
    "fig2, axes2 = plt.subplots(1,3, figsize=(28,10))\n",
    "for strip in range(0,3):\n",
    "    axis2 = axes2[strip] \n",
    "    data = projections[event][:,:,strip]\n",
    "    im2 = axis2.imshow(data, origin='lower', aspect='auto')    \n",
    "    axis2.set_xlabel(\"time bin\")\n",
    "    axis2.set_ylabel(projNames[strip]+\" strip\")\n",
    "    divider = make_axes_locatable(axis2)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.4)\n",
    "    fig2.colorbar(im2, cax=cax)\n",
    "    plt.subplots_adjust(bottom=0.15, left=0.05, right=0.95, wspace=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(normMergedImage))             # entries\n",
    "#print(len(normMergedImage[0]))          # strips\n",
    "#print(len(normMergedImage[0][0]))       # timebins\n",
    "#print(len(normMergedImage[0][0][0]))    # channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_transforms = {'train':transforms.Compose([transforms.ToTensor])}\n",
    "import TPCParser as io\n",
    "importlib.reload(io)\n",
    "tensor_data = torch.from_numpy(np.array(normMergedImage))\n",
    "tensor_data = tensor_data.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TPCParser as io\n",
    "importlib.reload(io)\n",
    "data = io.padTensorData(tensor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tensor_data.shape)\n",
    "#print(data.shape)\n",
    "#entry_index = 500  # Index of the entry to visualize\n",
    "#image_entry = data[entry_index]\n",
    "#plt.imshow(image_entry)\n",
    "#plt.axis('off')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kris/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/kris/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze the early layers\n",
    "for param in resnet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
