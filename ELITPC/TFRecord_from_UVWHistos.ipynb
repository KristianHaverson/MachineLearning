{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/04\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import numpy as np\n",
    "import ROOT\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecord related methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "################################################\n",
    "def _array_float32_feature(ndarray):\n",
    "    return lambda array: tf.train.Feature(float_list=tf.train.FloatList(value=array.reshape(-1)))\n",
    "################################################\n",
    "##FIXME: reduce precision to 32 bits\n",
    "################################################\n",
    "def _array_int64_feature(ndarray):\n",
    "    return lambda array: tf.train.Feature(int64_list=tf.train.Int64List(value=array.reshape(-1)))\n",
    "################################################\n",
    "################################################\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "################################################\n",
    "################################################\n",
    "def create_features(x, y):\n",
    "    dtype_feature_x = _array_float32_feature(x)\n",
    "    dtype_feature_y = _array_int64_feature(y)\n",
    "    d_feature = {}\n",
    "    d_feature['UVW_data'] = dtype_feature_x(x)\n",
    "    d_feature['label'] = dtype_feature_y(y)\n",
    "    features = tf.train.Features(feature = d_feature)\n",
    "    return features\n",
    "################################################\n",
    "################################################\n",
    "def createWriter(fileName):\n",
    "    result_tf_file = fileName + '.tfrecords'\n",
    "    writer = tf.io.TFRecordWriter(result_tf_file)\n",
    "    return writer, result_tf_file\n",
    "################################################\n",
    "################################################\n",
    "def saveSingleExampleToTFRecord(writer, features):\n",
    "    example = tf.train.Example(features = features)\n",
    "    serialized = example.SerializeToString()\n",
    "    writer.write(serialized)\n",
    "################################################\n",
    "################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods reading the ROOT files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "################################################\n",
    "def get_numpy_from_histo(root_histo):\n",
    "    nBinsX = root_histo.GetNbinsX()\n",
    "    nBinsY = root_histo.GetNbinsY()\n",
    "    nBinsY = 92 ##FIXME: Need uniform frame size\n",
    "    numpy_histo = np.zeros((nBinsX,nBinsY))\n",
    "    for iBinX in range(0, nBinsX):\n",
    "        for iBinY in range(0, nBinsY):\n",
    "            numpy_histo[iBinX, iBinY] = root_histo.GetBinContent(iBinX, iBinY)\n",
    "    return numpy_histo\n",
    "################################################\n",
    "##FIX ME: provide source of labels\n",
    "################################################\n",
    "def read_root(fileName, normalize=False):\n",
    "    projection_histos = {\"U\":0, \"V\":0, \"W\":0}\n",
    "    rootFile = ROOT.TFile(fileName,\"r\")\n",
    "    keysList = rootFile.GetListOfKeys()\n",
    "    numberOfHistos = len(keysList)\n",
    "    label = 0\n",
    "    index = 0\n",
    "    while index<numberOfHistos:\n",
    "        objName = keysList[index].GetName()\n",
    "        eventId = objName.split(\"evt\")[1]\n",
    "        for projName in projection_histos.keys():\n",
    "            histo_name = \"hraw_\"+projName+\"_vs_time_evt\"+eventId\n",
    "            root_histo = rootFile.Get(histo_name)\n",
    "            numpy_histo = get_numpy_from_histo(root_histo)\n",
    "            if normalize: \n",
    "                maxValue = np.amax(numpy_histo)\n",
    "                numpy_histo = np.where(numpy_histo<0,0,numpy_histo/maxValue)\n",
    "            print(\"histo name: \",histo_name,\" shape:\",numpy_histo.shape)\n",
    "            numpy_histo = np.pad(numpy_histo, ((0,0),(0,32),(0,0)))\n",
    "            print(\"histo name: \",histo_name,\" shape:\",numpy_histo.shape)\n",
    "            projection_histos[projName] = numpy_histo\n",
    "       \n",
    "        features = np.stack(arrays=list(projection_histos.values()), axis=2)\n",
    "        features_cropped = np.stack(arrays=list(projection_histos.values()), axis=2)\n",
    "        labels = np.array([0,0])\n",
    "        if index==0:\n",
    "            print(\"features.shape: \",features.shape)\n",
    "            print(\"labels.shape: \",labels.shape)\n",
    "        index += 3 \n",
    "        #print(\"eventId:\",eventId)\n",
    "        yield features, labels \n",
    "################################################\n",
    "##Test histogram reading\n",
    "################################################\n",
    "fileName = \"/scratch/akalinow/ProgrammingProjects/MachineLearning/ELITPC/data/UVWProjections_2018-06-19T15:13:33.941_0008.root\"\n",
    "for item in read_root(fileName):\n",
    "    print(item)\n",
    "    break\n",
    "    \n",
    "f = ROOT.TFile(fileName)\n",
    "h_U = f.Get(\"hraw_W_vs_time_evt15416\")\n",
    "c1 = ROOT.TCanvas()\n",
    "c1.Draw()\n",
    "h_U.Draw(\"col\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The final conversion methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 files\n",
      "features.shape:  (512, 92, 3)\n",
      "labels.shape:  (2,)\n",
      "Serializing 1927 examples into UVWProjections_2018-06-19T15:13:33.941_0008.tfrecords done!\n",
      "Execution time: 175.17 seconds\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "################################################\n",
    "def ROOT_to_TFRecord(normalize=False):\n",
    "    path = \"/scratch/akalinow/ProgrammingProjects/MachineLearning/ELITPC/data/\"\n",
    "    fileName = \"UVWProjections_2018-06-19T15:13:33.941_0008\"\n",
    "    number_of_files = len(glob.glob(path + \"*.root\"))\n",
    "    number_of_examples = 0\n",
    "    print (\"Found {} files\".format(number_of_files))\n",
    "    start_time = time.perf_counter()\n",
    "    writer, result_tf_file = createWriter(fileName)\n",
    "    for idx, file in enumerate(glob.glob(path + \"*.root\")):\n",
    "        \n",
    "        for numpy_histogram, labels in read_root(file, normalize=normalize):\n",
    "            features = create_features(numpy_histogram, labels)\n",
    "            saveSingleExampleToTFRecord(writer, features)\n",
    "            number_of_examples+=1\n",
    "        if idx == number_of_files - 1:\n",
    "            writer.close()\n",
    "            print (\"Serializing {} examples into {} done!\".format(number_of_examples,result_tf_file))\n",
    "            print(\"Execution time: {:.2f} seconds\".format(time.perf_counter() - start_time))\n",
    "################################################\n",
    "################################################\n",
    "ROOT_to_TFRecord(normalize=True)\n",
    "################################################\n",
    "################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the TFRecord format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresShape = (512, 92, 3)\n",
    "cropped_featuresShape = (64, 64, 3)\n",
    "labelsShape = (2,)\n",
    "################################################\n",
    "################################################\n",
    "feature_description = {\n",
    "    'UVW_data': tf.io.FixedLenFeature(featuresShape, tf.float32),\n",
    "    'label': tf.io.FixedLenFeature(labelsShape, tf.int64),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)\n",
    "################################################\n",
    "################################################\n",
    "def readTFRecordFile(fileNames):\n",
    "    raw_dataset = tf.data.TFRecordDataset(fileNames)\n",
    "    return raw_dataset.map(_parse_function)\n",
    "################################################\n",
    "################################################\n",
    "fileNames = [\"UVWProjections_2018-06-19T15:13:33.941_0008.tfrecords\"]\n",
    "dataset = readTFRecordFile(fileNames)\n",
    "\n",
    "for item in dataset.take(1):\n",
    "      print(repr(item))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
