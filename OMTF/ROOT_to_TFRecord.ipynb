{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/04\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import pathlib\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import ROOT\n",
    "import pandas as pd\n",
    "from root_pandas import read_root\n",
    "from root_numpy import root2array\n",
    "\n",
    "nLayers = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions of functions used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.array(['muonPt', 'muonEta', 'muonPhi', 'muonCharge', 'omtfPt', 'omtfEta',\n",
    "       'omtfPhi', 'omtfCharge', 'omtfScore', 'omtfQuality', 'omtfRefLayer',\n",
    "       'omtfProcessor', 'omtfFiredLayers', 'phiDist_0', 'phiDist_1',\n",
    "       'phiDist_2', 'phiDist_3', 'phiDist_4', 'phiDist_5', 'phiDist_6',\n",
    "       'phiDist_7', 'phiDist_8', 'phiDist_9', 'phiDist_10', 'phiDist_11',\n",
    "       'phiDist_12', 'phiDist_13', 'phiDist_14', 'phiDist_15', 'phiDist_16',\n",
    "       'phiDist_17'])\n",
    "\n",
    "def decodeUnion(raw, unionFormat):     \n",
    "    rawData = int(raw)\n",
    "    layer    = rawData &               0xff \n",
    "    quality = (rawData &             0xff00) >> 8\n",
    "    z       = (rawData &           0xff0000) >> 16 \n",
    "    eta   = 0\n",
    "    valid = 1\n",
    "    phiDist = 0     \n",
    "    if unionFormat==\"new\":\n",
    "        valid   = (rawData &         0xff000000) >> 24\n",
    "        eta     = (rawData &     0xffff00000000) >> 32\n",
    "        phiDist = (rawData & 0xffff000000000000) >> 48\n",
    "    else:\n",
    "        eta   = (rawData &         0xff000000) >> 24\n",
    "        phiDist     = (rawData &     0xffff00000000) >> 32 \n",
    "    if phiDist>=2**15 -1:\n",
    "        phiDist -= 2**16\n",
    "    return np.array([layer, quality, z, valid, eta, phiDist], dtype=np.int16)\n",
    "\n",
    "def decodeHits(hits, unionFormat):\n",
    "    phiDistArray = np.full(nLayers, 9999, dtype=np.int16)\n",
    "    for aHit in hits:\n",
    "        decodedUnion = decodeUnion(aHit, unionFormat)\n",
    "        np.put(phiDistArray, decodedUnion[0], decodedUnion[5])    \n",
    "    return phiDistArray  \n",
    "\n",
    "def transformColumns(df, unionFormat):\n",
    "    df[\"omtfFiredLayers\"] = df[\"omtfFiredLayers\"].transform(lambda x: np.binary_repr(x,18).count(\"1\"))\n",
    "    columnNames = [\"phiDist_{}\".format(iLayer) for iLayer in range(0, nLayers)]                         \n",
    "    for iLayer in range(0, nLayers):\n",
    "            df[\"phiDist_{}\".format(iLayer)] = df[\"hits\"].transform(lambda x: decodeHits(x, unionFormat)[iLayer]).astype('int16',copy=False)\n",
    "\n",
    "def loadDatasetFromParquet(parquetFile):\n",
    "    df = pd.read_parquet(parquetFile)\n",
    "    df = df.drop(columns=\"hits\")\n",
    "    df = df.sample(frac=1.0)\n",
    "    df.info(memory_usage='deep')\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(df.values)\n",
    "    return dataset\n",
    "\n",
    "def saveDatasetToTFRecord(dataset, fileName):  \n",
    "    dataset = dataset.map(lambda x: tf.cast(x, tf.float32))\n",
    "    dataset = dataset.map(tf.io.serialize_tensor)\n",
    "    writer = tf.data.experimental.TFRecordWriter(fileName, compression_type=\"GZIP\")\n",
    "    writer.write(dataset)\n",
    "    \n",
    "def parse_tensor(tensor):\n",
    "    return tf.io.parse_tensor(tensor, out_type=tf.float32)  \n",
    "\n",
    "def benchmark(dataset, num_epochs=1):\n",
    "    start_time = time.perf_counter()\n",
    "    count = 0\n",
    "    for epoch_num in range(num_epochs):\n",
    "        for sample in dataset:\n",
    "            count+=sample.shape[0]\n",
    "            # Performing a training step\n",
    "            time.sleep(1E-10)\n",
    "    tf.print(\"Number of examples: \",count)       \n",
    "    tf.print(\"Execution time:\", time.perf_counter() - start_time) \n",
    "    \n",
    "def convertROOT_2_Parquet_2_TFRecord(fileNames):\n",
    "    for fileName in fileNames: \n",
    "        print(\"Processing file:\",fileName)\n",
    "        label = fileName.split(\"/\")[-1].split(\".\")[0]\n",
    "        label = label.lstrip(\"omtfHits_omtfAlgo0x0006_v1\")\n",
    "        path = str(pathlib.Path(fileName).parent)\n",
    "        path = path.rstrip(\"omtfHits_omtfAlgo0x0006_v1\")\n",
    "        path = path.replace(\"ROOT\",\"Python/\")\n",
    "        for iChunk, dfChunk in enumerate(read_root(fileName, chunksize=int(15E6))):\n",
    "            print(\"\\tProcessing chunk: {}\".format(iChunk))\n",
    "            transformColumns(dfChunk, unionFormat=\"new\")  \n",
    "            parquetFile = path+'df.parquet_{}_chunk_{}.gzip'.format(label, iChunk)\n",
    "            dfChunk.to_parquet(parquetFile, compression='gzip')\n",
    "            dataset = loadDatasetFromParquet(parquetFile)\n",
    "            dataset = dataset.map(tf.io.serialize_tensor)\n",
    "            tfrecordFileName = path+'{}_chunk_{}.tfrecord.gzip'.format(label,iChunk)\n",
    "            writer = tf.data.experimental.TFRecordWriter(tfrecordFileName, compression_type=\"GZIP\")\n",
    "            writer.write(dataset)\n",
    "            print(\"Chunk done.\")\n",
    "            break\n",
    "        print(\"File done.\")\n",
    "         \n",
    "def convertParquet_2_TFRecord(fileNames, isTrain, doFilter):\n",
    "    for parquetFile in fileNames: \n",
    "        print(\"Processing file:\",parquetFile)\n",
    "        label = parquetFile.split(\"/\")[-1]\n",
    "        label = label.lstrip(\"df.parquet_\")\n",
    "        label = label.rstrip(\".gzip\")\n",
    "        path = str(pathlib.Path(parquetFile).parent)+\"/\"\n",
    "        dataset = loadDatasetFromParquet(parquetFile)\n",
    "        if doFilter:\n",
    "            print(\"Filtering.\")\n",
    "            dataset = filterDataset(dataset, isTrain)\n",
    "            label = label+\"_filtered\"\n",
    "            path = path+\"/filtered/\"\n",
    "        tfrecordFileName = path+label+'.tfrecord.gzip'\n",
    "        print(\"Saving to TFRecord file.\")\n",
    "        saveDatasetToTFRecord(dataset, tfrecordFileName) \n",
    "        print(\"File done.\")\n",
    "        \n",
    "def test(fileNames, isTrain, doFilter):\n",
    "    parquetFile = fileNames[0]\n",
    "    label = parquetFile.split(\"/\")[-1]\n",
    "    label = label.lstrip(\"omtfHits_omtfAlgo0x0006_v1df.parquet_\")\n",
    "    label = label.rstrip(\".gzip\")\n",
    "    path = str(pathlib.Path(parquetFile).parent)+\"/\"\n",
    "    if doFilter:\n",
    "        label = label+\"_filtered\"\n",
    "        path = path+\"/filtered/\"\n",
    "    tfrecordFileName = path+'{}.tfrecord_TEST.gzip'.format(label)\n",
    "    writer = tf.data.experimental.TFRecordWriter(tfrecordFileName, compression_type=\"GZIP\")\n",
    "       \n",
    "    for parquetFile in fileNames: \n",
    "        print(\"Processing file:\",parquetFile)\n",
    "        print(\"Loading parquet file.\")\n",
    "        dataset = loadDatasetFromParquet(parquetFile).take(10)\n",
    "        if doFilter:\n",
    "            print(\"Filtering.\")\n",
    "            dataset = filterDataset(dataset, isTrain)\n",
    "            \n",
    "        tfrecordFileName = path+label+'.tfrecord.gzip'\n",
    "        print(\"Saving to TFRecord file.\")\n",
    "        saveDatasetToTFRecord(dataset, tfrecordFileName)    \n",
    "        print(\"File done.\")        \n",
    "        \n",
    "                \n",
    "def filterDataset(dataset, isTrain):      \n",
    "    #Select positive muons (has to be done before batching)\n",
    "    #columnIndex = np.where(columns == \"omtfFiredLayers\")[0][0]\n",
    "    #dataset = dataset.filter(lambda x: x[columnIndex] != 1027)  \n",
    "    #Select muon with OMTF quality==12\n",
    "    #columnIndex = np.where(columns == \"omtfQuality\")[0][0]       \n",
    "    #dataset = dataset.filter(lambda x: x[columnIndex]>=12)\n",
    "    if isTrain:\n",
    "        #Select muon basing on generated pT\n",
    "        columnIndex = np.where(columns == \"muonPt\")[0][0]\n",
    "        dataset = dataset.filter(lambda x: x[columnIndex]<100)  \n",
    "    return dataset       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import ROOT files into Pandas DataFrame, and save into a parquet format, then transform into TFRecord\n",
    "This step should be executed only once. Later the data should be read from parquet or TFRecord files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames = glob.glob('/home/user1/scratch/akalinow/CMS/OverlapTrackFinder/Python/omtfHits/ROOT/omtfHits_omtfAlgo0x0006_v1/*.root')\n",
    "#fileNames = glob.glob('/home/user1/scratch/akalinow/CMS/OverlapTrackFinder/Python/omtfHits/ROOT/omtfHits_omtfAlgo0x0006_v1/*oldSample_files_*.root')\n",
    "\n",
    "print(fileNames)\n",
    "#convertROOT_2_Parquet_2_TFRecord(fileNames)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write TFRecord from parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/user1/scratch/akalinow/CMS/OverlapTrackFinder/Python/omtfHits/Python/df.parquet_OMTFHits_pats0x0003_oldSample_files_30_40_chunk_0.gzip', '/home/user1/scratch/akalinow/CMS/OverlapTrackFinder/Python/omtfHits/Python/df.parquet_OMTFHits_pats0x0003_oldSample_files_1_10_chunk_0.gzip', '/home/user1/scratch/akalinow/CMS/OverlapTrackFinder/Python/omtfHits/Python/df.parquet_OMTFHits_pats0x0003_oldSample_files_15_25_chunk_0.gzip', '/home/user1/scratch/akalinow/CMS/OverlapTrackFinder/Python/omtfHits/Python/df.parquet_OMTFHits_pats0x0003_newerSample_files_1_100_chunk_0.gzip']\n",
      "Processing file: /home/user1/scratch/akalinow/CMS/OverlapTrackFinder/Python/omtfHits/Python/df.parquet_OMTFHits_pats0x0003_oldSample_files_30_40_chunk_0.gzip\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13889489 entries, 2080389 to 3671668\n",
      "Data columns (total 31 columns):\n",
      "muonPt             float64\n",
      "muonEta            float64\n",
      "muonPhi            float64\n",
      "muonCharge         int32\n",
      "omtfPt             float64\n",
      "omtfEta            float64\n",
      "omtfPhi            float64\n",
      "omtfCharge         int32\n",
      "omtfScore          int32\n",
      "omtfQuality        int64\n",
      "omtfRefLayer       int64\n",
      "omtfProcessor      int32\n",
      "omtfFiredLayers    int64\n",
      "phiDist_0          int16\n",
      "phiDist_1          int16\n",
      "phiDist_2          int16\n",
      "phiDist_3          int16\n",
      "phiDist_4          int16\n",
      "phiDist_5          int16\n",
      "phiDist_6          int16\n",
      "phiDist_7          int16\n",
      "phiDist_8          int16\n",
      "phiDist_9          int16\n",
      "phiDist_10         int16\n",
      "phiDist_11         int16\n",
      "phiDist_12         int16\n",
      "phiDist_13         int16\n",
      "phiDist_14         int16\n",
      "phiDist_15         int16\n",
      "phiDist_16         int16\n",
      "phiDist_17         int16\n",
      "dtypes: float64(6), int16(18), int32(4), int64(3)\n",
      "memory usage: 1.7 GB\n",
      "Saving to TFRecord file.\n",
      "File done.\n",
      "Processing file: /home/user1/scratch/akalinow/CMS/OverlapTrackFinder/Python/omtfHits/Python/df.parquet_OMTFHits_pats0x0003_oldSample_files_1_10_chunk_0.gzip\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13892416 entries, 779025 to 8910753\n",
      "Data columns (total 31 columns):\n",
      "muonPt             float64\n",
      "muonEta            float64\n",
      "muonPhi            float64\n",
      "muonCharge         int32\n",
      "omtfPt             float64\n",
      "omtfEta            float64\n",
      "omtfPhi            float64\n",
      "omtfCharge         int32\n",
      "omtfScore          int32\n",
      "omtfQuality        int64\n",
      "omtfRefLayer       int64\n",
      "omtfProcessor      int32\n",
      "omtfFiredLayers    int64\n",
      "phiDist_0          int16\n",
      "phiDist_1          int16\n",
      "phiDist_2          int16\n",
      "phiDist_3          int16\n",
      "phiDist_4          int16\n",
      "phiDist_5          int16\n",
      "phiDist_6          int16\n",
      "phiDist_7          int16\n",
      "phiDist_8          int16\n",
      "phiDist_9          int16\n",
      "phiDist_10         int16\n",
      "phiDist_11         int16\n",
      "phiDist_12         int16\n",
      "phiDist_13         int16\n",
      "phiDist_14         int16\n",
      "phiDist_15         int16\n",
      "phiDist_16         int16\n",
      "phiDist_17         int16\n",
      "dtypes: float64(6), int16(18), int32(4), int64(3)\n",
      "memory usage: 1.7 GB\n",
      "Saving to TFRecord file.\n",
      "File done.\n",
      "Processing file: /home/user1/scratch/akalinow/CMS/OverlapTrackFinder/Python/omtfHits/Python/df.parquet_OMTFHits_pats0x0003_oldSample_files_15_25_chunk_0.gzip\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13882359 entries, 13304486 to 1524059\n",
      "Data columns (total 31 columns):\n",
      "muonPt             float64\n",
      "muonEta            float64\n",
      "muonPhi            float64\n",
      "muonCharge         int32\n",
      "omtfPt             float64\n",
      "omtfEta            float64\n",
      "omtfPhi            float64\n",
      "omtfCharge         int32\n",
      "omtfScore          int32\n",
      "omtfQuality        int64\n",
      "omtfRefLayer       int64\n",
      "omtfProcessor      int32\n",
      "omtfFiredLayers    int64\n",
      "phiDist_0          int16\n",
      "phiDist_1          int16\n",
      "phiDist_2          int16\n",
      "phiDist_3          int16\n",
      "phiDist_4          int16\n",
      "phiDist_5          int16\n",
      "phiDist_6          int16\n",
      "phiDist_7          int16\n",
      "phiDist_8          int16\n",
      "phiDist_9          int16\n",
      "phiDist_10         int16\n",
      "phiDist_11         int16\n",
      "phiDist_12         int16\n",
      "phiDist_13         int16\n",
      "phiDist_14         int16\n",
      "phiDist_15         int16\n",
      "phiDist_16         int16\n",
      "phiDist_17         int16\n",
      "dtypes: float64(6), int16(18), int32(4), int64(3)\n",
      "memory usage: 1.7 GB\n",
      "Saving to TFRecord file.\n",
      "File done.\n",
      "Processing file: /home/user1/scratch/akalinow/CMS/OverlapTrackFinder/Python/omtfHits/Python/df.parquet_OMTFHits_pats0x0003_newerSample_files_1_100_chunk_0.gzip\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 906742 entries, 293358 to 268208\n",
      "Data columns (total 31 columns):\n",
      "muonPt             906742 non-null float64\n",
      "muonEta            906742 non-null float64\n",
      "muonPhi            906742 non-null float64\n",
      "muonCharge         906742 non-null int32\n",
      "omtfPt             906742 non-null float64\n",
      "omtfEta            906742 non-null float64\n",
      "omtfPhi            906742 non-null float64\n",
      "omtfCharge         906742 non-null int32\n",
      "omtfScore          906742 non-null int32\n",
      "omtfQuality        906742 non-null int64\n",
      "omtfRefLayer       906742 non-null int64\n",
      "omtfProcessor      906742 non-null int32\n",
      "omtfFiredLayers    906742 non-null int64\n",
      "phiDist_0          906742 non-null int16\n",
      "phiDist_1          906742 non-null int16\n",
      "phiDist_2          906742 non-null int16\n",
      "phiDist_3          906742 non-null int16\n",
      "phiDist_4          906742 non-null int16\n",
      "phiDist_5          906742 non-null int16\n",
      "phiDist_6          906742 non-null int16\n",
      "phiDist_7          906742 non-null int16\n",
      "phiDist_8          906742 non-null int16\n",
      "phiDist_9          906742 non-null int16\n",
      "phiDist_10         906742 non-null int16\n",
      "phiDist_11         906742 non-null int16\n",
      "phiDist_12         906742 non-null int16\n",
      "phiDist_13         906742 non-null int16\n",
      "phiDist_14         906742 non-null int16\n",
      "phiDist_15         906742 non-null int16\n",
      "phiDist_16         906742 non-null int16\n",
      "phiDist_17         906742 non-null int16\n",
      "dtypes: float64(6), int16(18), int32(4), int64(3)\n",
      "memory usage: 114.1 MB\n",
      "Saving to TFRecord file.\n",
      "File done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-18 15:37:52.768860: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3444593272 exceeds 10% of system memory.\n",
      "2020-12-18 15:43:25.141010: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3445319168 exceeds 10% of system memory.\n",
      "2020-12-18 15:48:57.381674: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3442825032 exceeds 10% of system memory.\n"
     ]
    }
   ],
   "source": [
    "fileNames = glob.glob('/home/user1/scratch/akalinow/CMS/OverlapTrackFinder/Python/omtfHits/Python/df.parquet_*.gzip')\n",
    "\n",
    "print(fileNames)\n",
    "\n",
    "convertParquet_2_TFRecord(fileNames, isTrain = False, doFilter = False)       \n",
    "#test(fileNames, isTrain = False, doFilter = False)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: read Pandas df from parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames = glob.glob('/home/user1/scratch/akalinow/CMS/OverlapTrackFinder/Python/omtfHits/Python/df.parquet_OMTFHits_pats0x0003_oldSample_files_35_45_chunk_*.gzip')\n",
    "#df = pd.read_parquet(fileNames[0])\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: read TFRecord from TFRecord file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames = glob.glob('/home/user1/scratch/akalinow/CMS/OverlapTrackFinder/Python/omtfHits/Python/OMTFHits_pats0x0003_newerSample_files_1_100_chunk_0.tfrecord.gzip')\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset(fileNames, compression_type=\"GZIP\")\n",
    "dataset = raw_dataset.map(parse_tensor, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.batch(10000, drop_remainder=False)\n",
    "\n",
    "benchmark(raw_dataset.map(parse_tensor,num_parallel_calls=tf.data.experimental.AUTOTUNE))\n",
    "benchmark(raw_dataset.map(parse_tensor))\n",
    "benchmark(dataset)\n",
    "#benchmark(dataset.prefetch(tf.data.experimental.AUTOTUNE))\n",
    "#benchmark(tf.data.Dataset.range(2).interleave(dataset))\n",
    "\n",
    "for element in dataset.take(1): \n",
    "  print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
